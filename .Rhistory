q()
library(shiny); runApp('test.R')
runApp('test.R')
# Run the shiny app
shinyApp(ui = ui, server = server)
library(shiny)
library(shiny)
# Define the user interface
ui <- fluidPage(
sidebarLayout(
sidebarPanel(
selectInput("distribution", "Select Distribution:",
choices = c("Hypergeometric", "Beta")),
radioButtons("plot_type", "Select Plot Type:",
choices = c("discrete", "continous")),
conditionalPanel(condition = "input.distribution == 'Hypergeometric'",
numericInput("N", "N:", min = 1, value = 500),
numericInput("K", "K:", min = 0, value = 50),
numericInput("n", "n:", min = 0, value = 100)
),
conditionalPanel(condition = "input.distribution == 'Beta'",
numericInput("alpha", "alpha:", min = 0, value = 0.5),
numericInput("beta", "beta:", min = 0, value = 0.5)
),
sliderInput("sample_size", "Sample Size:", min = 1, max = 250, value = 30)
),
mainPanel(
plotOutput("dist_plot")
)
)
)
# Define the server logic
server <- function(input, output) {
# Create a reactive expression to generate the data
data <- reactive({
sample_size <- input$sample_size
if (input$distribution == "Hypergeometric") {
N <- input$N
K <- input$K
n <- input$n
rhyper(sample_size, N, K, n)
} else if (input$distribution == "Beta") {
alpha <- input$alpha
beta <- input$beta
rbeta(sample_size, alpha, beta)
}
})
# Create a reactive expression to generate the plot
output$dist_plot <- renderPlot({
if (input$plot_type == "discrete") {
hist(data(), main = "Histogram Distribution",
xlab = input$distribution)
} else if (input$plot_type == "continous") {
plot(density(data()), main = "Density Distribution",
xlab = input$distribution)
}
})
}
# Run the shiny app
shinyApp(ui = ui, server = server)
avocado <- read.csv('data/avocado-production.csv')
sweet_patato <- read.csv('data/sweet-potato-production.csv')
tomato <- read.csv('data/tomato-production.csv')
cereal <- read.csv('data/cereal-production.csv')
wheat <- read.csv('data/wheat-production.csv')
maize <- read.csv('data/maize-production.csv')
world_population <- read.csv('data/world-population.csv')
per_capita_vegetable_intake <- read.csv('per-capita-vegetable-intake.csv')
# For each country and crop (avocado, sweet potato, tomato, cereal, wheat, maize) calculate the average of the first ten recorded years and the last ten recorded years. For each of the
# crops: Which three countries have the highest increase in production from the first decade to the
# last decade? Which three countries have the highest decrease?
print(avocado)
head(cols <- textstat_collocations(tokens_guardian, size = 2, min_count = 2), 10)
head(cols <- textstat_collocations(tokens_telegraph, size = 2, min_count = 2), 10)
# Apply statistical analysis methods on the immigration news data:
#   https://fileshare.uibk.ac.at/f/6e513faa986443a48726/?dl=1
#   • Extract only articles published in 2016 by two newspapers (Guardian, Telegraph)
#   using corpus_subset()
#   • Perform tokenization and feature removal based on minimum frequency
#   • Identify several most similar words to the word “refugee” using textstat_simil()
#   • Compare representative words between the two newspaper sources
#   using textstat_keyness()
#   • Identify important multi-word proper nouns (capitalized words)
#   using textstat_collocations()
library(quanteda)
library(quanteda.textstats)
# Load the data
data_guardian <- readRDS("data_refugee_guardian.RDS")
# Apply statistical analysis methods on the immigration news data:
#   https://fileshare.uibk.ac.at/f/6e513faa986443a48726/?dl=1
#   • Extract only articles published in 2016 by two newspapers (Guardian, Telegraph)
#   using corpus_subset()
#   • Perform tokenization and feature removal based on minimum frequency
#   • Identify several most similar words to the word “refugee” using textstat_simil()
#   • Compare representative words between the two newspaper sources
#   using textstat_keyness()
#   • Identify important multi-word proper nouns (capitalized words)
#   using textstat_collocations()
library(quanteda)
library(quanteda.textstats)
# Load the data
data_guardian <- readRDS("data_refugee_guardian.RDS")
setwd("C:/Users/Th3RapidK1ller/Documents/LyricalEvolutionAnalysis")
# Read in the data
data <- read.csv("data.csv")
head(data)
# print column names
names(data)
setwd("C:/Users/Th3RapidK1ller/Documents/LyricalEvolutionAnalysis")
# Read in the data where language is English
data <- read.csv("data/lyrics.csv", header = TRUE, stringsAsFactors = FALSE)
setwd("C:/Users/Th3RapidK1ller/Documents/LyricalEvolutionAnalysis")
# Read in the data where language is English
data <- read.csv("data.csv", header = TRUE, stringsAsFactors = FALSE)
data <- data[data$language == "en",]
data
nrow(data)
# create a dataframe where songs are grouped by decade
decades <- data.frame(decade = c(1950, 1960, 1970, 1980, 1990, 2000, 2010))
View(decades)
df$year <- as.numeric(df$year)
nrow(data)
data$year <- as.numeric(data$year)
# Create a new column 'decade' by cutting the 'year' column into decades
data$decade <- cut(data$year, breaks = seq(1900, 2020, by = 10), labels = seq(1900, 2010, by = 10))
# Load the dplyr package
library(dplyr)
# Group the data by the 'decade' column
grouped_df <- data %>% group_by(decade)
# Print the result
print(grouped_df)
View(grouped_df)
View(data)
View(data)
View(data)
setwd("C:/Users/Th3RapidK1ller/Documents/LyricalEvolutionAnalysis")
# Read in the data where language is English
data <- read.csv("data.csv", header = TRUE, stringsAsFactors = FALSE)
data <- data[data$language == "en",]
# print the number of rows
nrow(data)
data$year <- as.numeric(data$year)
# Create a new column 'decade' by cutting the 'year' column into decades
data$decade <- cut(data$year, breaks = seq(1900, 2020, by = 10), labels = seq(1900, 2010, by = 10))
# Load the dplyr package
library(dplyr)
# Group the data by the 'decade' column
grouped_df <- data %>% group_by(decade)
# Print the result
print(grouped_df)
View(data)
setwd("C:/Users/Th3RapidK1ller/Documents/LyricalEvolutionAnalysis")
# Read in the data where language is English
data <- read.csv("data.csv", header = TRUE, stringsAsFactors = FALSE)
data <- data[data$language == "en",]
# print the number of rows
nrow(data)
data$year <- as.numeric(data$year)
View(data)
setwd("C:/Users/Th3RapidK1ller/Documents/LyricalEvolutionAnalysis")
# Read in the data where language is English
data <- read.csv("data.csv", header = TRUE, stringsAsFactors = FALSE)
data <- data[data$language == "en",]
View(data)
nrow(data)
data$year <- as.numeric(data$year)
# Create a new column 'decade' by cutting the 'year' column into decades
data$decade <- cut(data$year, breaks = seq(1900, 2020, by = 10), labels = seq(1900, 2010, by = 10))
# Load the dplyr package
library(dplyr)
# Group the data by the 'decade' column
grouped_df <- data %>% group_by(decade)
# Print the result
print(grouped_df)
data$year <- as.numeric(data$year)
# Create a new column 'decade' by cutting the 'year' column into decades
data$decade <- cut(data$year, breaks = seq(1950, 2010, by = 10), right = FALSE)
# Load the dplyr package
library(dplyr)
# Group the data by the 'decade' column
grouped_df <- data %>% group_by(decade)
# Print the result
print(grouped_df)
nrow(grouped_df)
data$decade <- cut(data$year, breaks = seq(1900, 2010, by = 10), right = FALSE)
# Load the dplyr package
library(dplyr)
# Group the data by the 'decade' column
grouped_df <- data %>% group_by(decade)
# Print the result
print(grouped_df)
nrow(grouped_df)
data$decade <- cut(data$year, breaks = seq(0, 2010, by = 10), right = FALSE)
# Load the dplyr package
library(dplyr)
# Group the data by the 'decade' column
grouped_df <- data %>% group_by(decade)
# Print the result
print(grouped_df)
nrow(grouped_df)
